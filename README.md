# üöÄ Projet : API RAG pour √âv√©nements Publics

Ce projet impl√©mente un syst√®me complet de RAG (Retrieval-Augmented Generation) expos√© via une API FastAPI. Il est con√ßu pour r√©pondre √† des questions sur des √©v√©nements publics en utilisant des documents sources.

Le projet est enti√®rement conteneuris√© avec Docker et d√©ploy√© via un pipeline CI/CD automatis√© utilisant GitHub Actions.

```
RAG_SYSTEM_PUBLIC_EVENTS/
‚îú‚îÄ‚îÄ .github/workflows/          # Dossier pour l'automatisation CI/CD
‚îÇ   ‚îî‚îÄ‚îÄ ci-cd.yml               # Fichier de workflow GitHub Actions (tests, build, push)
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Stockage des donn√©es (non versionn√© avec Git)
‚îÇ   ‚îî‚îÄ‚îÄ faiss_index/            # Dossier pour la base de donn√©es vectorielle
‚îÇ       ‚îú‚îÄ‚îÄ index.faiss         # Fichier binaire de l'index FAISS
‚îÇ       ‚îî‚îÄ‚îÄ index.pkl           # Fichier de mapping des documents (m√©tadonn√©es)
‚îÇ
‚îú‚îÄ‚îÄ src/                          # Le coeur de ton code ("source")
‚îÇ   ‚îú‚îÄ‚îÄ api/                    # Module pour l'API FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # Indique que 'api' est un package Python
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Point d'entr√©e de l'API (d√©finit les routes /query, etc.)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # D√©finit les mod√®les Pydantic (QueryRequest, etc.)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                   # Module pour toute la logique RAG
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # Indique que 'core' est un package Python
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py      # Fonctions pour charger les donn√©es sources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processing.py       # Fonctions pour nettoyer et "chunker" le texte
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py        # G√®re la connexion au mod√®le d'embedding (Mistral)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ faiss_manager.py    # G√®re la cr√©ation, sauvegarde et chargement de l'index FAISS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_service.py      # Le service principal qui re√ßoit une query et retourne une r√©ponse
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py         # Orchestre la cha√Æne LangChain (prompt + LLM + retriever)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (chatbot.py, query_app.py) # Autres logiques m√©tier
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ Tests/                    # Tes tests unitaires
‚îÇ       ‚îú‚îÄ‚îÄ test_api.py           # Teste les points de terminaison de l'API
‚îÇ       ‚îú‚îÄ‚îÄ test_data_loader.py   # Teste le chargement des donn√©es
‚îÇ       ‚îú‚îÄ‚îÄ test_processing.py    # Teste le nettoyage/chunking
‚îÇ       ‚îî‚îÄ‚îÄ test_embedding.py     # Teste la g√©n√©ration d'embeddings
‚îÇ
‚îú‚îÄ‚îÄ Scripts/                      # (Souvent scripts de build ou d'√©valuation)
‚îÇ   ‚îú‚îÄ‚îÄ build_index.py          # Script pour (re)construire l'index FAISS
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py             # Script pour lancer l'√©valuation Ragas
‚îÇ
‚îú‚îÄ‚îÄ .env                        # Fichier pour les secrets (MISTRAL_API_KEY). Ignor√© par Git.
‚îú‚îÄ‚îÄ .gitignore                  # Fichier listant les dossiers/fichiers √† ignorer par Git (.env, .venv, etc.)
‚îú‚îÄ‚îÄ .python-version             # (Optionnel) D√©finit la version Python du projet (ex: 3.12)
‚îú‚îÄ‚îÄ Dockerfile                  # "Recette" pour construire ton image Docker
‚îî‚îÄ‚îÄ pyproject.toml              # Fichier central ! D√©finit les d√©pendances, le nom du projet, etc.

```

## 1. Architecture du Syst√®me (Runtime)

Ce sch√©ma montre comment l'API fonctionne une fois qu'elle est lanc√©e dans un conteneur Docker.

```mermaid
graph TD
    subgraph "Client (Navigateur/Postman)"
        U(Utilisateur)
    end

    subgraph "Serveur (Conteneur Docker)"
        A[API FastAPI / Uvicorn]
        B(Service RAG)
        C[(Base Vectorielle FAISS)]
        D((LLM Externe: MistralAI))
    end
    
    subgraph "Processus d'Indexation (Offline)"
         E[Donn√©es Brutes] -- "scripts/build_index.py" --> C
    end

    U -- "1. Requ√™te HTTP /query" --> A
    A -- "2. Transmet la question" --> B
    B -- "3. Cr√©e un embedding de la question" --> C
    C -- "4. R√©cup√®re les documents similaires" --> B
    B -- "5. Construit le Prompt (contexte + question)" --> D
    D -- "6. G√©n√®re la r√©ponse" --> B
    B -- "7. Retourne la r√©ponse" --> A
    A -- "8. R√©ponse JSON" --> U
```

### R√¥le des Composants (Runtime)

  * **API (FastAPI / Uvicorn)**
      * **R√¥le :** C'est la porte d'entr√©e de l'application. Elle re√ßoit les requ√™tes HTTP (comme `/query`) de l'utilisateur, valide les donn√©es d'entr√©e (gr√¢ce √† Pydantic/Schemas) et les transmet au service RAG. Elle est servie par `Uvicorn`, un serveur web ASGI rapide.
  * **Service RAG (C≈ìur de l'application)**
      * **R√¥le :** C'est le cerveau de l'op√©ration. Il orchestre l'ensemble du processus RAG (√† l'aide de **LangChain**). Il prend la question de l'utilisateur, la transforme en vecteur, interroge la base **FAISS** pour trouver des documents pertinents, et enfin, construit un prompt complexe qu'il envoie √† **MistralAI**.
  * **Base Vectorielle (FAISS)**
      * **R√¥le :** C'est la m√©moire √† long terme du syst√®me. Elle stocke les "embeddings" (repr√©sentations vectorielles) des documents sources. Son travail est de trouver *tr√®s* rapidement les morceaux de texte les plus pertinents pour une question donn√©e.
  * **LLM Externe (MistralAI)**
      * **R√¥le :** C'est le g√©n√©rateur de texte. Il re√ßoit le prompt (contenant la question de l'utilisateur et le contexte trouv√© par FAISS) et g√©n√®re une r√©ponse en langage naturel. Il n√©cessite une cl√© API (`MISTRAL_API_KEY`) pour fonctionner.

---

## 2. Architecture CI/CD (D√©ploiement)

Ce sch√©ma montre comment le code est test√©, construit et d√©ploy√© automatiquement √† chaque modification.

```mermaid
graph LR
    subgraph "Poste du D√©veloppeur"
        A(Code Local) -- "1. git push" --> B(D√©p√¥t GitHub)
    end
    
    subgraph "CI/CD (Cloud GitHub)"
        B -- "2. D√©clenche" --> C[GitHub Actions]
        C -- "3. Lance les tests" --> D(pytest)
        C -- "4. Lance l'√©valuation" --> E(Ragas)
        C -- "5. Si succ√®s, build" --> F(Docker Build)
        F -- "6. Pousse l'image" --> G[(GHCR)]
    end
    
    subgraph "D√©mo (Local ou Serveur)"
        G -- "7. docker pull" --> H(Docker Desktop)
        H -- "8. docker run" --> I(Conteneur RAG)
    end
```

### R√¥le des Composants (CI/CD)

  * **D√©p√¥t GitHub**
      * **R√¥le :** Stocke l'int√©gralit√© du code source, y compris le `Dockerfile`, le `pyproject.toml` et les workflows d'Actions.
  * **GitHub Actions (`.github/workflows/ci-cd.yml`)**
      * **R√¥le :** C'est l'orchestrateur de l'automatisation. Il r√©agit √† un `git push` et ex√©cute une s√©rie d'√©tapes d√©finies :
        1.  **Tester (pytest) :** Lance les tests unitaires pour s'assurer que les fonctions de base du code sont correctes.
        2.  **√âvaluer (Ragas) :** Lance le script d'√©valuation (`scripts/evaluate.py`) pour mesurer la qualit√© des r√©ponses du RAG. C'est une √©tape cruciale de "CI pour IA".
        3.  **Construire (Docker Build) :** Si les tests et l'√©valuation r√©ussissent, il utilise le `Dockerfile` pour empaqueter l'application dans une image Docker.
  * **GitHub Container Registry (GHCR)**
      * **R√¥le :** C'est un service de stockage d'images Docker. L'image valid√©e par le pipeline y est "pouss√©e" (publi√©e) et versionn√©e (avec le tag `latest`).
  * **Docker Desktop (Serveur de D√©mo)**
      * **R√¥le :** C'est l'environnement d'ex√©cution. Il `pull` (t√©l√©charge) l'image depuis GHCR et la `run` (lance) en tant que conteneur, en lui injectant les cl√©s API via le fichier `.env`.

---

## 3. Composants Cl√©s du D√©p√¥t

  * `src/api/main.py`
      * **R√¥le :** D√©finit les points de terminaison (routes) de l'API FastAPI, comme `/query` et `/rebuild`.
  * `src/api/schemas.py`
      * **R√¥le :** D√©finit les mod√®les de donn√©es Pydantic pour la validation des requ√™tes et des r√©ponses.
  * `scripts/build_index.py`
      * **R√¥le :** Script manuel ou automatis√© pour lire les donn√©es brutes, les traiter, calculer leurs embeddings et construire la base de donn√©es vectorielle FAISS.
  * `scripts/evaluate.py`
      * **R√¥le :** Script utilis√© par le pipeline CI/CD pour √©valuer la pertinence et la fid√©lit√© des r√©ponses du RAG avec la biblioth√®que `ragas`.
  * `Dockerfile`
      * **R√¥le :** La "recette" pour construire l'image Docker. Il indique quelle version de Python utiliser, comment installer les d√©pendances (via `uv` et `pyproject.toml`) et quelle commande lancer au d√©marrage (`uvicorn`).
  * `pyproject.toml`
      * **R√¥le :** Fichier central de configuration du projet Python. Il liste toutes les d√©pendances (comme `fastapi`, `uvicorn`, `langchain`, `faiss-cpu`, etc.).

<!-- end list -->

## 4. Guide d'installation et d'ex√©cution

Il existe deux m√©thodes pour lancer ce projet : en utilisant l'image Docker pr√©-construite (recommand√© pour la production/d√©mo) ou en l'ex√©cutant localement (pour le d√©veloppement).

### M√©thode 1 : Lancer avec Docker (Recommand√©)

Cette m√©thode utilise l'image Docker d√©j√† test√©e et publi√©e sur le GitHub Container Registry (GHCR).

**Pr√©requis :**
* **Docker Desktop** (pour Windows/Mac) ou **Docker Engine** (pour Linux) doit √™tre install√©.

**√âtapes :**

1.  **Cr√©er un Personal Access Token (PAT) :**
    * Pour vous connecter √† GHCR, vous avez besoin d'un [PAT GitHub (classic)](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens#creating-a-personal-access-token-classic) avec **uniquement** la permission `read:packages`. Copiez ce token (ex: `ghp_...`).

2.  **Se connecter √† GHCR :**
    * Ouvrez un terminal et connectez-vous. Remplacez `VOTRE_NOM_UTILISATEUR` par le v√¥tre. Il vous demandera votre mot de passe : collez votre **PAT**.
    ```bash
    docker login ghcr.io -u VOTRE_NOM_UTILISATEUR
    ```

3.  **Cr√©er le fichier `.env` :**
    * Cr√©ez un fichier nomm√© `.env` dans un dossier de votre choix. Il doit contenir votre cl√© API :
    ```ini
    MISTRAL_API_KEY=votre_cle_mistral_commencant_par_...
    ```

4.  **T√©l√©charger l'image :**
    * T√©l√©chargez la derni√®re version de l'image (remplacez `ai-christopher/rag-system-public-events` par le nom de votre d√©p√¥t si diff√©rent).
    ```bash
    docker pull ghcr.io/ai-christopher/rag-system-public-events:latest
    ```

5.  **Lancer le conteneur :**
    * Depuis le dossier contenant votre fichier `.env`, lancez cette commande.
    ```bash
    docker run -d -p 8000:8000 --env-file .env ghcr.io/ai-christopher/rag-system-public-events:latest
    ```

6.  **V√©rifier :**
    * Votre API est maintenant accessible √† l'adresse `http://localhost:8000`. Vous pouvez aussi voir le conteneur avec une pastille verte "Running" dans Docker Desktop.

### M√©thode 2 : Lancer localement (Pour le d√©veloppement)

Cette m√©thode vous permet de lancer l'API directement sur votre machine pour tester des modifications rapidement.

**Pr√©requis :**
* **Python 3.12+**
* **`uv`** (ou `pip`)

**√âtapes :**

1.  **Cloner le d√©p√¥t :**
    ```bash
    git clone https://github.com/ai-christopher/rag-system-public-events.git
    cd rag-system-public-events
    ```

2.  **Cr√©er un environnement virtuel :**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # Sur Windows: .\.venv\Scripts\activate
    ```

3.  **Installer les d√©pendances :**
    * Nous utilisons `uv` pour une installation rapide.
    ```bash
    pip install uv
    uv pip install -e .  # Le '-e' l'installe en mode "√©ditable"
    ```

4.  **Cr√©er le fichier `.env` :**
    * Cr√©ez un fichier `.env` √† la racine du projet avec votre cl√© :
    ```ini
    MISTRAL_API_KEY=votre_cle_mistral_commencant_par_...
    ```

5.  **Lancer le serveur de d√©veloppement :**
    * `uvicorn` d√©marrera l'API avec le rechargement automatique (`--reload`).
    ```bash
    uvicorn src.api.main:app --host 127.0.0.1 --port 8000 --reload
    ```

6.  **V√©rifier :**
    * Votre API est accessible √† l'adresse `http://localhost:8000`.

---

## 5. Exemples d'utilisation de l'API

Une fois l'API lanc√©e (avec Docker ou localement), vous pouvez interagir avec elle.

### Documentation interactive (Recommand√©)

Le moyen le plus simple d'explorer l'API est d'utiliser la documentation int√©gr√©e (gr√¢ce √† FastAPI/Swagger) :

* **Documentation Swagger :** `http://localhost:8000/docs`

Depuis l'interface Swagger, vous pouvez voir tous les points de terminaison, leurs descriptions, et m√™me les essayer directement depuis votre navigateur.

### Exemples avec `curl` (Terminal)

Vous pouvez utiliser `curl` depuis votre terminal pour interroger l'API.

#### Interroger le RAG

* **Endpoint :** `POST /ask`
* **Description :** Pose une question au syst√®me RAG.
* **Commande :**

```bash
curl -X 'POST' \
  'http://localhost:8000/ask' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "question": "Quelle est la date du prochain √©v√©nement ?"
}'
````

  * **R√©ponse attendue (Exemple) :**

<!-- end list -->

```json
{
  "response": "Le prochain √©v√©nement aura lieu le 15 d√©cembre.",
  "source_documents": [
    {
      "page_content": "La conf√©rence annuelle est pr√©vue pour le 15 d√©cembre...",
      "metadata": { "source": "doc1.pdf" }
    }
  ]
}
```

#### Reconstruire l'index (si impl√©ment√©)

  * **Endpoint :** `POST /rebuild`
  * **Description :** D√©clenche le script de reconstruction de l'index en arri√®re-plan.
  * **Commande :**

<!-- end list -->

```bash
curl -X 'POST' \
  'http://localhost:8000/rebuild' \
  -H 'accept: application/json' \
  -d ''
```

  * **R√©ponse attendue (Exemple) :**

<!-- end list -->

```json
{
  "status": "success",
  "message": "Index reconstruit avec succ√®s √† partir de 50 documents."
}
```

### Exemple avec Python (`requests`)

Vous pouvez aussi appeler l'API depuis un autre script Python.

```python
import requests

# L'URL de votre API locale
api_url = "http://localhost:8000/query"

# La question √† poser
payload = {
    "query": "Quels sont les th√®mes principaux de la conf√©rence ?"
}

try:
    response = requests.post(api_url, json=payload)
    response.raise_for_status()  # L√®ve une exception si erreur HTTP

    # Afficher la r√©ponse
    data = response.json()
    print("R√©ponse de l'API :")
    print(data.get("response"))

except requests.exceptions.RequestException as e:
    print(f"Erreur lors de l'appel √† l'API : {e}")

```

---

## 6. Choix Techniques, Limites et Am√©liorations

Cette section justifie les d√©cisions d'architecture prises pour ce projet et identifie les pistes d'am√©lioration.

### Justification des Choix

* **Architecture (FastAPI + Docker + CI/CD)**
    * **FastAPI** a √©t√© choisi pour ses hautes performances, sa documentation automatique (Swagger/ReDoc) et son utilisation moderne de la validation de donn√©es avec Pydantic.
    * **Docker** a √©t√© utilis√© pour encapsuler l'application. Cela garantit une portabilit√© totale : l'API s'ex√©cutera de la m√™me mani√®re sur le PC d'un d√©veloppeur, dans un pipeline CI/CD, ou sur un serveur de production.
    * **GitHub Actions (CI/CD)** a √©t√© impl√©ment√© pour automatiser la validation (tests, √©valuation) et la livraison (build/push Docker), r√©duisant les erreurs humaines et garantissant que seule une version stable du code est publi√©e.

* **Composants RAG**
    * **Mod√®le (MistralAI)** : Les mod√®les Mistral offrent un √©quilibre de premier plan entre performance (qualit√© des r√©ponses) et efficacit√© (vitesse, co√ªt). Leur forte comp√©tence en fran√ßais √©tait un atout pour ce projet.
    * **Base Vectorielle (FAISS)** : FAISS (d√©velopp√© par Meta) est une biblioth√®que extr√™mement rapide et efficace pour la recherche de similarit√© sur de grands ensembles de vecteurs. Son int√©gration "in-memory" (fichiers `index.faiss` et `index.pkl`) la rend parfaite pour un d√©ploiement simple et rapide sans d√©pendre d'une base de donn√©es externe.
    * **√âvaluation (Ragas)** : Utiliser `pytest` seul ne suffit pas pour un projet d'IA. `Ragas` a √©t√© choisi car c'est le standard de l'industrie pour l'√©valuation des pipelines RAG. Il nous permet de mesurer objectivement des m√©triques cruciales comme la **fid√©lit√©** (l'API n'invente-t-elle rien ?) et la **pertinence** (la r√©ponse est-elle utile ?).

### Limites Actuelles

1.  **Mise √† jour des donn√©es :** La base FAISS est statique. Si de nouveaux √©v√©nements sont ajout√©s aux sources de donn√©es, l'API ne les conna√Ætra pas tant que l'index n'est pas manuellement reconstruit (`scripts/build_index.py`).
2.  **Scalabilit√© de l'index :** FAISS s'ex√©cute en m√©moire. Si la quantit√© de documents sources devait augmenter massivement (milliards de documents), cette architecture atteindrait ses limites de RAM.
3.  **Absence de m√©moire de conversation :** L'API traite chaque question de mani√®re ind√©pendante. Elle ne peut pas g√©rer les questions de suivi (par exemple, "Et o√π se situe-t-il ?" en r√©f√©rence √† la r√©ponse pr√©c√©dente).

### Am√©liorations Possibles

* **Automatiser le Re-indexing :** Ajouter un point de terminaison d'API s√©curis√© (`/rebuild_index`) qui peut √™tre appel√© par un service externe (ex: un cron job) pour reconstruire l'index chaque nuit.
* **Base de Donn√©es Vectorielle Manag√©e :** Pour une scalabilit√© sup√©rieure, migrer de FAISS vers une solution de base de donn√©es vectorielle h√©berg√©e (ex: Pinecone, Weaviate, Zilliz).
* **Impl√©menter l'historique de chat :** Modifier l'API pour qu'elle accepte un `session_id` afin de g√©rer l'historique de la conversation et permettre des interactions plus naturelles.

---

## 7. Validation et R√©sultats des Tests

Le projet est valid√© par deux niveaux de tests : des tests unitaires (`pytest`) pour la logique du code et une √©valuation de performance (`Ragas`) pour la qualit√© de l'IA.

### Tests Unitaires (Pytest)

Le pipeline CI/CD ex√©cute la suite de tests unitaires sur chaque `push`. Ces tests couvrent les modules critiques de l'application :

* `Tests/test_api.py` (3 tests)
* `Tests/test_data_loader.py` (4 tests)
* `Tests/test_embedding.py` (4 tests)
* `Tests/test_processing.py` (3 tests)

**R√©sultat :**
```

============================= 14 passed in 346.73s (0:05:46) =============================

```
*Tous les 14 tests unitaires passent avec succ√®s, garantissant que les composants de base (API, chargement de donn√©es, traitement) fonctionnent comme attendu.*

### √âvaluation de la Qualit√© RAG (Ragas)

Nous √©valuons la qualit√© des r√©ponses du RAG sur un jeu de donn√©es de test (`evaluate.py`). Les seuils de validation stricts sont activ√©s dans le pipeline CI.

**R√©sum√© des m√©triques (sur le jeu de test) :**

| M√©trique | Score Obtenu | Seuil Requis (CI) | Description |
| :--- | :---: | :---: | :--- |
| **Faithfulness (Fid√©lit√©)** | **1.00** / 1.00 | 0.8 | La r√©ponse est-elle factuellement bas√©e sur le contexte ? (Pas d'hallucination) |
| **Answer Relevancy** | **0.88** / 1.00 | - | La r√©ponse est-elle pertinente par rapport √† la question ? |
| **Context Precision** | **0.875** / 1.00 | 0.5 | Les contextes r√©cup√©r√©s sont-ils tous pertinents ? |
| **Context Recall** | **1.00** / 1.00 | - | Tous les contextes n√©cessaires ont-ils √©t√© r√©cup√©r√©s ? |

**Analyse des r√©sultats :**

* **Scores Parfaits (1.0) :** Les scores de `faithfulness` et `context_recall` sont parfaits. Cela signifie que l'API **n'invente aucune information** et qu'elle **r√©cup√®re syst√©matiquement le bon document** pour r√©pondre.
* **Scores √âlev√©s (0.88 - 0.875) :** Les scores de pertinence sont excellents et bien au-dessus des seuils.
* **Cas d'analyse (ID 3) :** Le seul cas o√π la `context_precision` a baiss√© (0.5) est la question sur "No√´l √† Montpellier". L'API a r√©cup√©r√© un document sur une "Soir√©e jeux", qui n'√©tait pas pertinent. Cependant, la `faithfulness` de 1.0 montre que le mod√®le a g√©r√© cette situation en d√©clarant qu'il n'avait pas d'information, ce qui est le comportement attendu (il n'a pas "hallucin√©" un √©v√©nement de No√´l).

**Conclusion :** Le pipeline RAG d√©montre une tr√®s haute qualit√©, avec une fiabilit√© (fid√©lit√©) parfaite et une excellente pertinence, validant ainsi l'architecture technique choisie.